# Instala si no lo tienes (descomenta)
# install.packages(c("stringr", "stringdist", "e1071"))

library(data.table)
library(stringr)
library(stringdist)
library(e1071)
library(dplyr)

# Asume dt es tu data.table con la columna ESTABLECIMIENTO
# Normalización con stringr
dt[, EST_NORMALIZADO := str_to_lower(ESTABLECIMIENTO)]
dt[, EST_NORMALIZADO := str_remove_all(EST_NORMALIZADO, "[0-9*+\\.@#$&_:|-]|www|\\.com|\\.ga|\\.pe|\\.au|\\.fra|\\.on")]
dt[, EST_NORMALIZADO := str_squish(str_replace_all(EST_NORMALIZADO, "\\s+", " "))]

# Extrae únicos de la versión normalizada
unique_est_norm <- unique(dt$EST_NORMALIZADO)
original_map <- dt[, .(EST_NORMALIZADO, ESTABLECIMIENTO)]

# Calcula matriz de distancias
dist_mat <- stringdistmatrix(unique_est_norm, unique_est_norm, method = "jw")

# Convierte a matriz simétrica para fuzzy
dist_matrix <- as.matrix(dist_mat)
diag(dist_matrix) <- 0  # Diagonal a 0

# Aplica Fuzzy C-Means (ajusta centers basado en codo, m=2 para fuzziness media)
fcm_result <- cmeans(dist_matrix, centers = 5, m = 2, iter.max = 100, verbose = TRUE)

# Asigna clusters (el de mayor membresía)
clusters <- apply(fcm_result$membership, 1, which.max)

# Crea dataframe con resultados
clustered_norm <- data.frame(
  EST_NORMALIZADO = unique_est_norm,
  Cluster = clusters,
  Membership = apply(fcm_result$membership, 1, max)  # Membresía máxima para revisión
)

# Une de vuelta a dt
dt_clustered <- dt %>%
  left_join(clustered_norm, by = "EST_NORMALIZADO")

# Resume: muestra originales únicos por cluster
dt_clustered %>%
  group_by(Cluster) %>%
  summarise(Establecimientos = paste(unique(ESTABLECIMIENTO), collapse = ", ")) %>%
  print()

# Opcional: Filtra por membresía baja (posible ruido)
dt_clustered[Membership < 0.6, .(ESTABLECIMIENTO, EST_NORMALIZADO, Membership)]
