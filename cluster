# Instala si no lo tienes (descomenta)
# install.packages(c("stringr", "stringdist"))

library(data.table)
library(stringr)
library(stringdist)
library(dplyr)  # Para summarise, opcional

# Asume dt es tu data.table con la columna ESTABLECIMIENTO
# Normalización con stringr: ignora case, números, especiales y dominios web
dt[, EST_NORMALIZADO := str_to_lower(ESTABLECIMIENTO)]  # A minúsculas
dt[, EST_NORMALIZADO := str_remove_all(EST_NORMALIZADO, "[0-9*+.]|www|\\.com|\\.ga|\\.pe|\\.au|\\.fra|\\.on")]  # Quita números, *, +, puntos, dominios
dt[, EST_NORMALIZADO := str_squish(str_replace_all(EST_NORMALIZADO, "\\s+", " "))]  # Limpia espacios múltiples y bordes

# Extrae únicos de la versión normalizada (para eficiencia)
unique_est_norm <- unique(dt$EST_NORMALIZADO)
original_map <- dt[, .(EST_NORMALIZADO, ESTABLECIMIENTO)]  # Mapa para recuperar originales

# Calcula matriz de distancias en normalizados (Jaro-Winkler para variaciones)
dist_mat <- stringdistmatrix(unique_est_norm, unique_est_norm, method = "jw")

# Convierte a dist
dist_obj <- as.dist(dist_mat)

# Clustering jerárquico
hc <- hclust(dist_obj, method = "complete")  # O "ward.D2"

# Visualiza dendrograma
plot(hc, labels = unique_est_norm, main = "Dendrograma de Establecimientos Normalizados", cex = 0.6)
rect.hclust(hc, k = 10)  # Ajusta k según veas

# Corta el árbol
clusters <- cutree(hc, h = 0.3)  # Ajusta h (0.2-0.4 para grupos similares)

# Crea dataframe con normalizados únicos y clusters
clustered_norm <- data.frame(
  EST_NORMALIZADO = unique_est_norm,
  Cluster = clusters
)

# Une de vuelta a dt
dt_clustered <- dt %>%
  left_join(clustered_norm, by = "EST_NORMALIZADO")

# Resume: muestra originales únicos por cluster
dt_clustered %>%
  group_by(Cluster) %>%
  summarise(Establecimientos = paste(unique(ESTABLECIMIENTO), collapse = ", ")) %>%
  print()

# O filtra un cluster
dt_clustered[Cluster == 1, .(ESTABLECIMIENTO, EST_NORMALIZADO)]